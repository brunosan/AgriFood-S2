{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "import numpy as np\n",
    "import openai\n",
    "import configparser\n",
    "\n",
    "#importing local modules\n",
    "from tokenize_sentences2db import openai_embeddings,log\n",
    "\n",
    "\n",
    "# Function to perform the search\n",
    "def search(query, model, db_config,number_of_results):\n",
    "    # Encode the query\n",
    "    log(\"Encoding the query...\")\n",
    "    query_embedding = openai_embeddings(model,query)[0]\n",
    "    log(\"Finding the most similar projects...\")\n",
    "    # Connect to the database\n",
    "    with psycopg2.connect(**db_config) as conn:\n",
    "        c = conn.cursor()\n",
    "\n",
    "        # Search for the top projects by cosine similarity\n",
    "        c.execute(\"\"\"\n",
    "            SELECT project_id, chunk, embedding <=> %s::VECTOR AS distance\n",
    "            FROM embeddings_openai\n",
    "            ORDER BY distance ASC\n",
    "            LIMIT %s;\n",
    "        \"\"\", (list(query_embedding), number_of_results))\n",
    "        \n",
    "        results = c.fetchall()\n",
    "    log(\"Done! Found {} results.\".format(len(results)))\n",
    "    return results\n",
    "\n",
    "# Function to generate a summary using OpenAI\n",
    "def generate_summary(question, context_sections, query):\n",
    "    prompt = f\"\"\"\n",
    "    You are a World Bank expert with access to all Bank projects who loves\n",
    "    to help people! Given the following Question and top answers, provide a\n",
    "    summary of the top results that answers the question and refers to the\n",
    "    results, whith links, outputted in markdown format. Use only the provided \n",
    "    results to create your answer.\n",
    "    If you are unsure say why and offer a similar question that might\n",
    "    point the users and you in the right direction.\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "\n",
    "    Top hits ordered by cosine similarity of the snippet embedding to the query embedding:\n",
    "    {context_sections}\n",
    "    \"\"\"\n",
    "\n",
    "    # In production, we should handle possible errors\n",
    "    completion_response = openai.Completion.create(\n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_tokens=512,  # Choose the max allowed tokens in completion\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            model='text-davinci-003')\n",
    "\n",
    "    return completion_response.choices[0].text.strip()\n",
    "\n",
    "def manage_results(projects,query,results):\n",
    "    # Create a string with the results\n",
    "    results_text = \"\"\n",
    "    for project_id, chunk, distance in results:\n",
    "        project = None\n",
    "        for p in projects:\n",
    "            if \",\".join(p[\"ids\"]) == project_id:\n",
    "                project = p\n",
    "                break\n",
    "        results_text += f\"\\nProject ID: {project_id}\\n\"\n",
    "        results_text += f\"Project title: {project['title']}\\n\"\n",
    "        results_text += f\"Project url: {project['url']}\\n\"\n",
    "        results_text += f\"Project abstract: {project['abstract']}\\n\"\n",
    "        results_text += f\"Relevant snippet: {chunk}\\n\"\n",
    "        results_text += f\"Distance: {distance}\\n\"\n",
    "\n",
    "    # Generate the summary using OpenAI\n",
    "    log(\"Generating summary...\")\n",
    "    summary = generate_summary(query, results_text, query)\n",
    "    return summary, results_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model=\"text-embedding-ada-002\"\n",
    "    number_of_results = 5\n",
    "\n",
    "    # Database configuration\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "\n",
    "    db_config = {\n",
    "        'dbname':   config['DB']['dbname'],\n",
    "        'user':     config['DB']['user'],\n",
    "        'password': config['DB']['password'],\n",
    "        'host':     config['DB']['host'],\n",
    "        'port':     int(config['DB']['port'])\n",
    "    }  \n",
    "\n",
    "    # Load the projects\n",
    "    with open(\"digital_agriculture_projects.json\", \"r\") as f:\n",
    "        projects = json.load(f)\n",
    "    # Define the query\n",
    "    query = \"Main challengues and oportunities to deploy Satellite Remote sensing for fertilizer management.\"\n",
    "    # Perform the search\n",
    "    results = search(query, model, db_config,number_of_results)\n",
    "    summary, results_text = manage_results(projects,query,results)\n",
    "    # Print the summary\n",
    "    log(summary)\n",
    "    log(results_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
