{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bdae4e044f4784a71b2760b6b1b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77bf61b99064c7d81003ef7e0d275a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95c8f17df4745c8a370a37edfed1847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05889bb194414b2e83ff76de21eea13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd3b53041fc4c44b844d5dca78368d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_embeddings(text: str, model: SentenceTransformer) -> np.ndarray:\n",
    "    return model.encode([text],show_progress_bar=True)\n",
    "\n",
    "import re\n",
    "\n",
    "def get_phrases(text: str) -> List[str]:\n",
    "    # Replace line breaks with spaces\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Split the text into phrases using a regex that matches punctuation marks\n",
    "    phrases = re.split('[.!?]', text)\n",
    "    # Remove leading and trailing spaces from each phrase\n",
    "    phrases = [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "    return phrases\n",
    "\n",
    "def get_most_relevant_files(query: str, folder_path: str, model: SentenceTransformer) -> List[Tuple[str, List[Tuple[str, float]]]]:\n",
    "    query_embedding = get_embeddings(query, model)\n",
    "    file_results = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                phrases = get_phrases(content)\n",
    "                phrase_embeddings = model.encode(phrases, show_progress_bar=True)\n",
    "                similarities = cosine_similarity(query_embedding, phrase_embeddings)\n",
    "                sorted_indices = np.argsort(similarities[0])[::-1]\n",
    "                sorted_phrases_similarities = [(phrases[i], similarities[0][i]) for i in sorted_indices]\n",
    "                file_results.append((filename, sorted_phrases_similarities))\n",
    "\n",
    "    return file_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load the model\n",
    "    model_name = \"sentence-transformers/paraphrase-distilroberta-base-v2\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Define the query and folder path\n",
    "    query = \"Remote sensing for fertilizer management\"\n",
    "    folder_path = \"text_files\"\n",
    "\n",
    "    # Get the most relevant files\n",
    "    most_relevant_files = get_most_relevant_files(query, folder_path, model)\n",
    "\n",
    "    # Sort the results by the highest similarity score in each document\n",
    "    most_relevant_files.sort(key=lambda x: x[1][0][1], reverse=True)\n",
    "\n",
    "    # Print the top 5 results\n",
    "    for filename, phrase_similarities in most_relevant_files[:5]:\n",
    "        print(f\"Filename: {filename}\")\n",
    "        for phrase, similarity in phrase_similarities[:1]:  # Print only the top relevant sentence\n",
    "            print(f\"  {phrase}: {similarity}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
